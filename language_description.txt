

?<varname> => as parameter
$<varname> => input

!sequence # if this model accepts sequential tensors.
!loss <<loss function>>
!optimizer(<<epoch>>) <<optimizer function>>(<<optimizer hyperparameter>>)
!activator <<activator function>>
model LinearRegression:
    Y ?= ?a*$1



assign value:
    parse value tree
    assign all values of terminal
    all value names must be like ___<is_parameter>_<num>
    only watches rvalue except ?=(reflect function)

assign process:
    copy original source

pp=r'[\+\-\*\/\@\s]'

<<n,m>>     [__pp__].   <<autogen>>       => <<n,m>>  [__pp__]     torch.FloatTensor(n,m,require_grads=True)
<<n,m>>     @           <<autogen>>(<j>)  => <<n,m>>  @            torch.FloatTensor(m,j,require_grads=True)

<<autogen>>       [__pp__]    <<n,m>>     => torch.FloatTensor(n,m,require_grads=True) [__pp__]   <<n,m>> 
<<autogen>>(<j>)  @           <<n,m>>     => torch.FloatTensor(j,n,require_grads=True) @          <<n,m>>


#auto conversion is not yet supported.


#internally torch's
linspace(-math.pi, 1.*math.pi, 2000, dtype=dtype) => torch.linspace(-math.pi, 1.*math.pi, 2000, dtype=dtype)



order:
" ? " -> " <<autogen>> " :
    r'\?({pp})' -> '<<autogen>>\1'
" ?(4) " -> "<<autogen>>(4)" :
    r'\?(\([\d.]+\))' -> '<<autogen>>\1'
" ?2.1 " -> "torch.FloatTensor([2.1],require_grads=True)" :
    r'\?([\d.]+)' -> 'torch.FloatTensor([\1],require_grads=True)'